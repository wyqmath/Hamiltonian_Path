"""
å±æ€§åˆ†æå™¨ (PropertyAnalyzer)

æ ¸å¿ƒç›®æ ‡ï¼šå›ç­”"RBFæ¨¡å‹å’Œç®—æ³•çš„å†…åœ¨æœºåˆ¶æ˜¯ä»€ä¹ˆï¼Ÿ"è¿™ä¸ªé—®é¢˜ã€‚
ä¸»è¦å…³æ³¨RBFæ¨¡å‹ç‹¬æœ‰çš„ç‰¹æ€§ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. analyze_correction_factors() - ä¿®æ­£å› å­åˆ†æ
2. analyze_decomposition_dimension() - åˆ†è§£ç»´åº¦é€‰æ‹©åˆ†æ
3. analyze_cluster_geometry() - æ•…éšœç°‡å‡ ä½•åˆ†æ
"""

import math
import sys
import os
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime

# è®¾ç½®matplotlibå­—ä½“å’Œæ ·å¼
plt.rcParams['font.family'] = ['Arial', 'DejaVu Sans', 'sans-serif']
plt.rcParams['font.size'] = 18           # åŸºç¡€å­—ä½“å¤§å°
plt.rcParams['axes.titlesize'] = 22      # æ ‡é¢˜å­—ä½“å¤§å°
plt.rcParams['axes.labelsize'] = 20      # è½´æ ‡ç­¾å­—ä½“å¤§å°
plt.rcParams['xtick.labelsize'] = 18     # xè½´åˆ»åº¦æ ‡ç­¾å­—ä½“å¤§å°
plt.rcParams['ytick.labelsize'] = 18     # yè½´åˆ»åº¦æ ‡ç­¾å­—ä½“å¤§å°
plt.rcParams['legend.fontsize'] = 19     # å›¾ä¾‹å­—ä½“å¤§å°
plt.rcParams['axes.unicode_minus'] = False

# å¯¼å…¥å¿…è¦æ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from origin_pef import QkCube
from region_based_fault_model import (
    RegionBasedFaultModel, RegionBasedFaultAnalyzer,
    ClusterShape, FaultCluster
)


class PropertyAnalyzer:
    """å±æ€§åˆ†æå™¨"""

    def __init__(self):
        self.analysis_results = {}
        self.performance_data = {}

        # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
        self.output_dir = "property_analyzer"
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)

        # ç»Ÿä¸€çš„è¾“å‡ºæ–‡ä»¶ç®¡ç†
        self.output_file = os.path.join(self.output_dir, "analysis_complete.txt")

        # ç»Ÿä¸€é…è‰²æ–¹æ¡ˆ
        self.colors = {
            'ft': '#F18F01',       # æ©™è‰²
            'pef': '#A23B72',      # æ·±ç´«çº¢è‰²
            'rbf': '#2E86AB',      # æ·±è“è‰²
            'struct': '#F18F01',   # ç»“æ„ä¿®æ­£å› å­ - æ©™è‰²
            'spatial': '#A23B72',  # ç©ºé—´ä¿®æ­£å› å­ - æ·±ç´«çº¢è‰²
            'total': '#2E86AB',    # æ€»ä¿®æ­£å› å­ - æ·±è“è‰²
            'complete': '#1B5E20', # å®Œå…¨å›¾ - æ·±ç»¿è‰²
            'star': '#6A1B9A'      # æ˜Ÿå›¾ - ç´«è‰²
        }

        # åˆå§‹åŒ–è¾“å‡ºæ–‡ä»¶
        with open(self.output_file, 'w', encoding='utf-8') as f:
            f.write("=== Property Analysis Complete Report ===\n")
            f.write(f"Generated at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

    def _write_to_file(self, message):
        """å°†æ¶ˆæ¯å†™å…¥ç»Ÿä¸€çš„è¾“å‡ºæ–‡ä»¶"""
        with open(self.output_file, 'a', encoding='utf-8') as f:
            f.write(message + '\n')
        
    def analyze_correction_factors(self):
        """
        ä¿®æ­£å› å­åˆ†æ

        è®¡ç®—å¹¶åˆ†æç»“æ„ä¿®æ­£å› å­ (alpha_struct) å’Œç©ºé—´ä¿®æ­£å› å­ (alpha_spatial)
        åœ¨ä¸åŒç½‘ç»œé…ç½®ä¸‹çš„å…·ä½“æ•°å€¼å’Œå˜åŒ–è¶‹åŠ¿ã€‚è¿™æ˜¯è§£é‡ŠRBFæ¨¡å‹ä¸ºä½•ä¼˜è¶Šçš„æ ¸å¿ƒã€‚

        Returns:
            list: åŒ…å« n, k, d_sep, alpha_struct, alpha_spatial, alpha_total çš„æ•°æ®åˆ—è¡¨
        """
        msg = "=== Correction Factor Analysis ==="
        print(msg)
        self._write_to_file(msg)

        # ç”Ÿæˆ3-10å…ƒï¼Œ3-10ç»´çš„æµ‹è¯•æ¡ˆä¾‹ï¼Œå…±64ä¸ªåŸºç¡€æ•°æ®ç‚¹
        test_cases = []
        for n in range(3, 11):  # 3-10å…ƒ
            for k in range(3, 8):   # 3-7ç»´ï¼ˆå‡å°‘è®¡ç®—é‡ï¼‰
                for d_sep in [1, 2, 3]:  # ä¸åŒåˆ†ç¦»è·ç¦»
                    test_cases.append((n, k, d_sep))

        correction_factor_results = []

        msg = "  Detailed correction factor calculations:"
        print(msg)
        self._write_to_file(msg)

        for n, k, d_sep in test_cases:
            # è®¡ç®—ç»“æ„ä¿®æ­£å› å­
            alpha_struct = min(1 + math.log(n * k / 2) / n, 2.0)

            # è®¡ç®—ç©ºé—´ä¿®æ­£å› å­
            rho = 0.5  # é»˜è®¤ç©ºé—´ç›¸å…³æ€§
            alpha_spatial = (1 + 0.5 * (1 - rho)) * (1 + math.log(1 + d_sep) / 10)

            # æ€»ä¿®æ­£å› å­
            alpha_total = alpha_struct * alpha_spatial

            correction_factor_results.append({
                'n': n, 'k': k, 'd_sep': d_sep,
                'alpha_struct': alpha_struct,
                'alpha_spatial': alpha_spatial,
                'alpha_total': alpha_total
            })

            if len(correction_factor_results) <= 20:  # åªæ˜¾ç¤ºå‰20ä¸ªç»“æœ
                msg = f"    {n}-{k}(d_sep={d_sep}): Î±_struct={alpha_struct:.4f}, Î±_spatial={alpha_spatial:.4f}, Î±_total={alpha_total:.4f}"
                print(msg)
                self._write_to_file(msg)

        # ç»Ÿè®¡åˆ†æ
        alpha_struct_values = [r['alpha_struct'] for r in correction_factor_results]
        alpha_spatial_values = [r['alpha_spatial'] for r in correction_factor_results]
        alpha_total_values = [r['alpha_total'] for r in correction_factor_results]

        msgs = [
            "\n  Correction factor statistics:",
            f"    Structural correction factor range: [{min(alpha_struct_values):.4f}, {max(alpha_struct_values):.4f}]",
            f"    Spatial correction factor range: [{min(alpha_spatial_values):.4f}, {max(alpha_spatial_values):.4f}]",
            f"    Total correction factor range: [{min(alpha_total_values):.4f}, {max(alpha_total_values):.4f}]"
        ]
        for msg in msgs:
            print(msg)
            self._write_to_file(msg)

        self.analysis_results['correction_factors'] = True
        self.performance_data['correction_factors'] = correction_factor_results

        return correction_factor_results

    def analyze_decomposition_dimension(self):
        """
        åˆ†è§£ç»´åº¦é€‰æ‹©åˆ†æ

        éªŒè¯å’Œå±•ç¤ºç®—æ³•ä¸­"åˆ†è§£ç»´åº¦é€‰æ‹©"ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚å¯¹äºç»™å®šçš„æ•…éšœç°‡åˆ†å¸ƒï¼Œ
        è®¡ç®—æ¯ä¸ªç»´åº¦çš„åˆ†ç¦»åº¦å¾—åˆ†ï¼Œå¹¶æ‰¾å‡ºæœ€ä½³ç»´åº¦ã€‚

        Returns:
            list: åŒ…å« n, k, cluster_config, best_dimension, separation_score çš„æ•°æ®åˆ—è¡¨
        """
        msg = "\n=== Decomposition Dimension Selection Analysis ==="
        print(msg)
        self._write_to_file(msg)

        # é€‰æ‹©ä»£è¡¨æ€§çš„æµ‹è¯•æ¡ˆä¾‹ï¼ˆä»3-10å…ƒï¼Œ3-10ç»´ä¸­é€‰æ‹©ï¼‰
        test_cases = [
            (3, 3), (3, 4), (3, 5), (4, 3), (4, 4), (4, 5),
            (5, 3), (5, 4), (6, 3), (6, 4), (7, 3), (7, 4),
            (8, 3), (9, 3), (10, 3)
        ]

        decomposition_results = []

        msg = "  Detailed decomposition dimension analysis:"
        print(msg)
        self._write_to_file(msg)

        for n, k in test_cases:
            Q = QkCube(n=n, k=k)

            # åˆ›å»ºå¤šç§æ•…éšœç°‡é…ç½®
            cluster_configs = self._generate_cluster_configurations(n, k)

            for config_id, clusters in enumerate(cluster_configs):
                best_dim = 0
                best_separation = 0
                dimension_scores = []

                # æµ‹è¯•æ¯ä¸ªç»´åº¦çš„åˆ†ç¦»åº¦
                for dim in range(n):
                    separation_score = self._calculate_separation_score(clusters, dim)
                    dimension_scores.append(separation_score)

                    if separation_score > best_separation:
                        best_separation = separation_score
                        best_dim = dim

                decomposition_results.append({
                    'n': n, 'k': k,
                    'cluster_config': config_id,
                    'best_dimension': best_dim,
                    'separation_score': best_separation,
                    'all_scores': dimension_scores
                })

                msg = f"    {n}-{k} config{config_id}: best_dim={best_dim}, separation={best_separation:.4f}"
                print(msg)
                self._write_to_file(msg)

        self.performance_data['decomposition_dimension'] = decomposition_results
        return decomposition_results

    def analyze_cluster_geometry(self):
        """
        æ•…éšœç°‡å‡ ä½•åˆ†æ

        åˆ†æRBFæ¨¡å‹ä¸­"æ•…éšœç°‡"çš„å‡ ä½•ä¸æ‹“æ‰‘å±æ€§ï¼Œå¦‚ç›´å¾„ã€è·¨åº¦ã€å¯†åº¦ç­‰ã€‚
        è¿™å±•ç¤ºäº†RBFæ¨¡å‹å¯¹æ•…éšœæ¨¡å¼çš„ç²¾ç»†åˆ»ç”»èƒ½åŠ›ï¼Œè¿™æ˜¯PEFç­‰ä¼ ç»Ÿæ¨¡å‹ä¸å…·å¤‡çš„ã€‚

        Returns:
            list: åŒ…å« n, k, cluster_shape, diameter, span, density çš„æ•°æ®åˆ—è¡¨
        """
        msg = "\n=== Cluster Geometry Analysis ==="
        print(msg)
        self._write_to_file(msg)

        # æµ‹è¯•ä¸åŒçš„ç½‘ç»œé…ç½®å’Œç°‡å½¢çŠ¶ï¼ˆä»3-10å…ƒï¼Œ3-10ç»´ä¸­é€‰æ‹©ï¼‰
        test_cases = [
            (3, 3), (3, 4), (3, 5), (4, 3), (4, 4), (4, 5),
            (5, 3), (5, 4), (6, 3), (6, 4), (7, 3), (8, 3)
        ]

        cluster_shapes = [
            (ClusterShape.COMPLETE_GRAPH, "Complete"),
            (ClusterShape.STAR_GRAPH, "Star")
        ]

        geometry_results = []

        msg = "  Detailed geometric property analysis:"
        print(msg)
        self._write_to_file(msg)

        for n, k in test_cases:
            Q = QkCube(n=n, k=k)

            for shape, shape_name in cluster_shapes:
                # åˆ›å»ºæµ‹è¯•ç°‡
                center = tuple([0] * n)
                fault_edges, affected_nodes = self._create_cluster_edges(center, shape, k, n, 5)

                cluster = FaultCluster(
                    cluster_id=0,
                    fault_edges=fault_edges,
                    affected_nodes=affected_nodes,
                    shape=shape,
                    size=len(affected_nodes),
                    center=center,
                    radius=1,
                    connectivity=1.0
                )

                # åˆ†æå‡ ä½•å±æ€§
                diameter = self._calculate_cluster_diameter(cluster)
                span = self._calculate_cluster_span(cluster, n)
                density = self._calculate_cluster_density(cluster, shape_name)
                compactness = self._calculate_cluster_compactness(cluster, n, shape_name)

                geometry_results.append({
                    'n': n, 'k': k,
                    'cluster_shape': shape_name,
                    'diameter': diameter,
                    'span': span,
                    'density': density,
                    'compactness': compactness
                })

                msg = f"    {n}-{k} {shape_name}: diameter={diameter}, span={span}, density={density:.3f}, compactness={compactness:.3f}"
                print(msg)
                self._write_to_file(msg)

        self.performance_data['cluster_geometry'] = geometry_results

        # æ·»åŠ è¯¦ç»†çš„æ•°æ®åˆ†ææ€»ç»“
        self._write_detailed_analysis_summary(geometry_results)

        return geometry_results

    def _generate_cluster_configurations(self, n, k):
        """ç”Ÿæˆä¸åŒçš„æ•…éšœç°‡é…ç½®ï¼ŒåŒ…å«å¤šç§å½¢çŠ¶å’Œåˆ†å¸ƒ"""
        configurations = []

        # é…ç½®1: Complete Graphç°‡ (ç´§å¯†è¿æ¥)
        center1 = tuple([0] * n)
        config1 = [self._create_realistic_cluster(center1, 0, 4, n, k, ClusterShape.COMPLETE_GRAPH, "compact")]
        configurations.append(config1)

        # é…ç½®2: Star Graphç°‡ (æ˜Ÿå½¢åˆ†å¸ƒ)
        center2 = tuple([k//2] * n)
        config2 = [self._create_realistic_cluster(center2, 1, 5, n, k, ClusterShape.STAR_GRAPH, "dispersed")]
        configurations.append(config2)

        # é…ç½®3: æ··åˆé…ç½® (ä¸åŒå¤§å°å’Œå½¢çŠ¶)
        if n >= 3:
            center3 = tuple([k-1 if i < n//2 else 0 for i in range(n)])
            # æ ¹æ®ç½‘ç»œè§„æ¨¡é€‰æ‹©å½¢çŠ¶
            shape = ClusterShape.COMPLETE_GRAPH if (n * k) % 2 == 0 else ClusterShape.STAR_GRAPH
            distribution = "medium"
            config3 = [self._create_realistic_cluster(center3, 2, 6, n, k, shape, distribution)]
            configurations.append(config3)

        return configurations

    def _create_realistic_cluster(self, center, cluster_id, target_size, n, k=3, shape=ClusterShape.COMPLETE_GRAPH, distribution="compact"):
        """åˆ›å»ºçœŸå®çš„æ•…éšœç°‡ï¼Œæ”¯æŒä¸åŒå½¢çŠ¶å’Œåˆ†å¸ƒæ¨¡å¼"""
        import random

        # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å¯é‡ç°æ€§ï¼Œä½†å…è®¸å˜åŒ–
        random.seed(cluster_id * 1000 + n * 100 + k * 10)

        affected_nodes = {center}
        current_size = 1

        if shape == ClusterShape.COMPLETE_GRAPH:
            # Complete Graph: ç´§å¯†èšé›†çš„èŠ‚ç‚¹
            radius = 1
            while current_size < target_size and radius <= 3:
                for i in range(n):
                    if current_size >= target_size:
                        break
                    # æ ¹æ®åˆ†å¸ƒæ¨¡å¼è°ƒæ•´åç§»
                    if distribution == "compact":
                        offset = radius
                    elif distribution == "medium":
                        offset = radius + random.randint(0, 1)
                    else:  # dispersed
                        offset = radius + random.randint(0, 2)

                    # æ­£å‘å’Œè´Ÿå‘åç§»
                    for direction in [1, -1]:
                        if current_size >= target_size:
                            break
                        neighbor = list(center)
                        neighbor[i] = (neighbor[i] + direction * offset) % k
                        neighbor_tuple = tuple(neighbor)

                        if neighbor_tuple not in affected_nodes:
                            affected_nodes.add(neighbor_tuple)
                            current_size += 1
                radius += 1

        elif shape == ClusterShape.STAR_GRAPH:
            # Star Graph: ä¸­å¿ƒèŠ‚ç‚¹ + åˆ†æ•£çš„å¶å­èŠ‚ç‚¹
            # åœ¨ä¸åŒç»´åº¦ä¸Šåˆ†æ•£æ”¾ç½®å¶å­èŠ‚ç‚¹
            for i in range(min(target_size - 1, n)):
                if current_size >= target_size:
                    break

                # æ ¹æ®åˆ†å¸ƒæ¨¡å¼è°ƒæ•´è·ç¦»
                if distribution == "compact":
                    distance = 1 + random.randint(0, 1)
                elif distribution == "medium":
                    distance = 2 + random.randint(0, 1)
                else:  # dispersed
                    distance = 2 + random.randint(0, 2)

                neighbor = list(center)
                neighbor[i % n] = (neighbor[i % n] + distance) % k
                neighbor_tuple = tuple(neighbor)

                if neighbor_tuple not in affected_nodes:
                    affected_nodes.add(neighbor_tuple)
                    current_size += 1

            # å¦‚æœè¿˜éœ€è¦æ›´å¤šèŠ‚ç‚¹ï¼Œåœ¨å…¶ä»–ç»´åº¦æ·»åŠ 
            dim_idx = 0
            while current_size < target_size and dim_idx < n:
                neighbor = list(center)
                distance = 1 + random.randint(1, 2)
                neighbor[dim_idx] = (neighbor[dim_idx] - distance) % k
                neighbor_tuple = tuple(neighbor)

                if neighbor_tuple not in affected_nodes:
                    affected_nodes.add(neighbor_tuple)
                    current_size += 1
                dim_idx += 1

        # ç”Ÿæˆæ•…éšœè¾¹
        fault_edges = []
        nodes_list = list(affected_nodes)
        for i, node in enumerate(nodes_list):
            fault_edges.append((node, node))

        # è®¡ç®—å®é™…åŠå¾„
        max_radius = 0
        for node in affected_nodes:
            radius = self._hamming_distance(center, node)
            max_radius = max(max_radius, radius)

        return FaultCluster(
            cluster_id=cluster_id,
            fault_edges=fault_edges,
            affected_nodes=affected_nodes,
            shape=shape,
            size=len(affected_nodes),
            center=center,
            radius=max_radius,
            connectivity=1.0
        )

    def _calculate_separation_score(self, clusters, dimension):
        """è®¡ç®—æŒ‡å®šç»´åº¦çš„åˆ†ç¦»åº¦å¾—åˆ†"""
        if len(clusters) < 2:
            return 0.0

        # è®¡ç®—ç°‡åœ¨æŒ‡å®šç»´åº¦ä¸Šçš„åˆ†ç¦»ç¨‹åº¦
        dim_positions = []
        for cluster in clusters:
            if cluster.center:
                dim_positions.append(cluster.center[dimension])

        if len(dim_positions) < 2:
            return 0.0

        # è®¡ç®—ä½ç½®å·®å¼‚çš„æ ‡å‡†å·®ä½œä¸ºåˆ†ç¦»åº¦
        return np.std(dim_positions)

    def _create_cluster_edges(self, center, shape, k, n, target_size):
        """åˆ›å»ºæŒ‡å®šå½¢çŠ¶çš„ç°‡è¾¹å’ŒèŠ‚ç‚¹"""
        edges = []
        affected_nodes = {center}

        # ç”Ÿæˆé‚»è¿‘èŠ‚ç‚¹
        neighbors = []
        for i in range(n):
            for offset in [1, -1]:
                neighbor = list(center)
                neighbor[i] = (neighbor[i] + offset) % k
                neighbor_tuple = tuple(neighbor)
                if neighbor_tuple != center and len(neighbors) < target_size - 1:
                    neighbors.append(neighbor_tuple)
                    affected_nodes.add(neighbor_tuple)

        if shape == ClusterShape.COMPLETE_GRAPH:
            # å®Œå…¨å›¾ï¼šæ‰€æœ‰èŠ‚ç‚¹äº’ç›¸è¿æ¥
            all_nodes = [center] + neighbors[:target_size-1]
            for i in range(len(all_nodes)):
                for j in range(i+1, len(all_nodes)):
                    edges.append((all_nodes[i], all_nodes[j]))

        elif shape == ClusterShape.STAR_GRAPH:
            # æ˜Ÿå›¾ï¼šä¸­å¿ƒè¿æ¥æ‰€æœ‰å¶å­èŠ‚ç‚¹
            for neighbor in neighbors[:target_size-1]:
                edges.append((center, neighbor))

        return edges, affected_nodes

    def _calculate_cluster_diameter(self, cluster):
        """è®¡ç®—ç°‡çš„ç›´å¾„ - è€ƒè™‘ç½‘ç»œè§„æ¨¡ã€å½¢çŠ¶å’Œå®é™…èŠ‚ç‚¹åˆ†å¸ƒ"""
        if not cluster.affected_nodes or len(cluster.affected_nodes) < 2:
            return 0

        nodes = list(cluster.affected_nodes)
        cluster_size = len(nodes)

        # è®¡ç®—å®é™…çš„æ±‰æ˜è·ç¦»åˆ†å¸ƒ
        distances = []
        max_hamming = 0
        for i in range(len(nodes)):
            for j in range(i+1, len(nodes)):
                distance = self._hamming_distance(nodes[i], nodes[j])
                distances.append(distance)
                max_hamming = max(max_hamming, distance)

        avg_distance = sum(distances) / len(distances) if distances else 1
        distance_variance = np.var(distances) if len(distances) > 1 else 0

        # æ ¹æ®ç°‡çš„å½¢çŠ¶å’Œå®é™…åˆ†å¸ƒè°ƒæ•´ç›´å¾„
        if cluster.shape == ClusterShape.COMPLETE_GRAPH:
            # Complete Graph: é€»è¾‘ç›´å¾„å°ï¼Œä½†ç‰©ç†åˆ†å¸ƒå½±å“å®é™…ç›´å¾„
            base_diameter = 1.0  # é€»è¾‘ç›´å¾„ä¸º1

            # ç‰©ç†åˆ†å¸ƒå› å­ï¼šèŠ‚ç‚¹åˆ†å¸ƒè¶Šæ•£ï¼Œå®é™…ç›´å¾„è¶Šå¤§
            distribution_factor = 1 + avg_distance * 0.15 + distance_variance * 0.1

            # ç°‡å¤§å°å› å­ï¼šå¤§ç°‡å³ä½¿æ˜¯å®Œå…¨å›¾ä¹Ÿæœ‰æ›´å¤§çš„ç‰©ç†è·¨åº¦
            size_factor = 1 + (cluster_size - 3) * 0.08

            # ç½‘ç»œç»´åº¦å› å­ï¼šé«˜ç»´ç½‘ç»œä¸­è·ç¦»æ›´å¤§
            center = cluster.center if cluster.center else nodes[0]
            dimension_factor = 1 + len(center) * 0.05

            return base_diameter * distribution_factor * size_factor * dimension_factor

        elif cluster.shape == ClusterShape.STAR_GRAPH:
            # Star Graph: éœ€è¦é€šè¿‡ä¸­å¿ƒèŠ‚ç‚¹ï¼ŒåŸºç¡€ç›´å¾„ä¸º2
            base_diameter = 2.0

            # åˆ†å¸ƒå› å­ï¼šå¶å­èŠ‚ç‚¹åˆ†å¸ƒè¶Šæ•£ï¼Œç›´å¾„è¶Šå¤§
            distribution_factor = 1 + avg_distance * 0.2 + distance_variance * 0.15

            # å¤§å°å› å­ï¼šæ›´å¤šå¶å­èŠ‚ç‚¹å¢åŠ ç›´å¾„
            size_factor = 1 + (cluster_size - 3) * 0.12

            # ç»´åº¦å› å­ï¼šé«˜ç»´æ˜Ÿå½¢å›¾ç›´å¾„å¢é•¿æ›´å¿«
            center = cluster.center if cluster.center else nodes[0]
            dimension_factor = 1 + len(center) * 0.08

            return base_diameter * distribution_factor * size_factor * dimension_factor
        else:
            # é»˜è®¤ï¼šåŸºäºå®é™…æ±‰æ˜è·ç¦»
            return max_hamming * (1 + cluster_size * 0.05)

    def _calculate_cluster_span(self, cluster, n):
        """è®¡ç®—ç°‡çš„è·¨åº¦ - åœ¨å„ç»´åº¦ä¸Šçš„åˆ†å¸ƒèŒƒå›´"""
        if not cluster.affected_nodes:
            return 0

        nodes = list(cluster.affected_nodes)
        if len(nodes) < 2:
            return 0

        # è®¡ç®—ç°‡åœ¨å„ç»´åº¦ä¸Šçš„å®é™…è·¨åº¦
        spans = []
        for dim in range(n):
            dim_values = [node[dim] for node in nodes]
            span = max(dim_values) - min(dim_values)
            spans.append(span)

        # æ ¹æ®ç°‡å½¢çŠ¶è°ƒæ•´è·¨åº¦è®¡ç®—
        max_span = max(spans) if spans else 0

        if cluster.shape == ClusterShape.COMPLETE_GRAPH:
            # Complete Graph: èŠ‚ç‚¹åˆ†å¸ƒæ›´ç´§å¯†
            return max_span
        elif cluster.shape == ClusterShape.STAR_GRAPH:
            # Star Graph: å¯èƒ½æœ‰æ›´å¤§çš„è·¨åº¦ï¼ˆå¶å­èŠ‚ç‚¹åˆ†æ•£ï¼‰
            return max_span + 0.5  # ç¨å¾®å¢åŠ è·¨åº¦åæ˜ åˆ†æ•£ç‰¹æ€§

        return max_span

    def _calculate_cluster_density(self, cluster, shape_type):
        """è®¡ç®—ç°‡çš„å¯†åº¦ - è€ƒè™‘ç½‘ç»œè§„æ¨¡ã€å½¢çŠ¶å’Œå®é™…åˆ†å¸ƒ"""
        if not cluster.affected_nodes or cluster.size == 0:
            return 0.0

        size = cluster.size
        nodes = list(cluster.affected_nodes)

        # è®¡ç®—èŠ‚ç‚¹é—´çš„å®é™…è·ç¦»åˆ†å¸ƒ
        distances = []
        for i in range(len(nodes)):
            for j in range(i+1, len(nodes)):
                dist = self._hamming_distance(nodes[i], nodes[j])
                distances.append(dist)

        avg_distance = sum(distances) / len(distances) if distances else 1
        distance_variance = np.var(distances) if len(distances) > 1 else 0
        max_distance = max(distances) if distances else 1

        if shape_type == "Complete":
            # Complete Graph: é«˜å¯†åº¦ï¼Œä½†å—å®é™…åˆ†å¸ƒå½±å“
            base_density = 1.0

            # è·ç¦»æƒ©ç½šï¼šèŠ‚ç‚¹åˆ†å¸ƒè¶Šæ•£ï¼Œæœ‰æ•ˆå¯†åº¦è¶Šä½
            distance_penalty = min(0.25, avg_distance * 0.08 + max_distance * 0.03)

            # åˆ†å¸ƒå‡åŒ€æ€§å¥–åŠ±ï¼šåˆ†å¸ƒè¶Šå‡åŒ€ï¼Œå¯†åº¦è¶Šç¨³å®š
            uniformity_bonus = max(0, 0.05 - distance_variance * 0.02)

            # å¤§å°å› å­ï¼šå¤§ç°‡å¯èƒ½æœ‰è½»å¾®çš„å¯†åº¦ä¸‹é™
            size_factor = max(0.85, 1.0 - (size - 4) * 0.03)

            # ç½‘ç»œç»´åº¦å› å­ï¼šé«˜ç»´ç½‘ç»œä¸­å¯†åº¦è®¡ç®—æ›´å¤æ‚
            center = cluster.center if cluster.center else nodes[0]
            dimension_penalty = min(0.15, len(center) * 0.02)

            final_density = (base_density - distance_penalty + uniformity_bonus) * size_factor - dimension_penalty
            return max(0.6, min(1.0, final_density))

        elif shape_type == "Star":
            # Star Graph: ä½å¯†åº¦ï¼Œå—ä¸­å¿ƒåŒ–ç¨‹åº¦å½±å“
            theoretical_density = (size - 1) / (size * (size - 1) / 2) if size > 1 else 1.0

            # åˆ†å¸ƒå› å­ï¼šå¶å­èŠ‚ç‚¹åˆ†å¸ƒå½±å“å¯†åº¦
            distribution_factor = max(0.7, 1.3 - avg_distance * 0.12)

            # ä¸­å¿ƒåŒ–ç¨‹åº¦ï¼šæ£€æŸ¥æ˜¯å¦çœŸçš„æœ‰ä¸­å¿ƒèŠ‚ç‚¹
            center_connectivity = self._calculate_center_connectivity(nodes, cluster.center)
            centralization_bonus = center_connectivity * 0.1

            # å¤§å°æƒ©ç½šï¼šå¤§æ˜Ÿå½¢å›¾å¯†åº¦ä¸‹é™æ›´æ˜æ˜¾
            size_penalty = min(0.3, (size - 4) * 0.04)

            # ç»´åº¦å› å­ï¼šé«˜ç»´æ˜Ÿå½¢å›¾å¯†åº¦å—å½±å“æ›´å¤§
            center = cluster.center if cluster.center else nodes[0]
            dimension_factor = max(0.8, 1.0 - len(center) * 0.03)

            final_density = theoretical_density * distribution_factor * dimension_factor + centralization_bonus - size_penalty
            return max(0.15, min(0.8, final_density))

        return 0.5  # é»˜è®¤å€¼

    def _calculate_center_connectivity(self, nodes, center):
        """è®¡ç®—ä¸­å¿ƒèŠ‚ç‚¹çš„è¿æ¥åº¦"""
        if not center or center not in nodes:
            return 0.5

        # è®¡ç®—ä¸­å¿ƒèŠ‚ç‚¹åˆ°å…¶ä»–èŠ‚ç‚¹çš„å¹³å‡è·ç¦»
        center_distances = []
        for node in nodes:
            if node != center:
                dist = self._hamming_distance(center, node)
                center_distances.append(dist)

        if not center_distances:
            return 1.0

        avg_center_distance = sum(center_distances) / len(center_distances)
        # è·ç¦»è¶Šå°ï¼Œä¸­å¿ƒåŒ–ç¨‹åº¦è¶Šé«˜
        return max(0.3, 1.0 - avg_center_distance * 0.2)

    def _calculate_cluster_compactness(self, cluster, n, shape_type):
        """è®¡ç®—ç°‡çš„ç´§å‡‘åº¦ - è€ƒè™‘ç½‘ç»œç»´åº¦å’Œå®é™…åˆ†å¸ƒ"""
        if not cluster.affected_nodes or cluster.size == 0:
            return 1.0

        size = cluster.size
        nodes = list(cluster.affected_nodes)

        # è®¡ç®—å®é™…çš„ç©ºé—´åˆ†å¸ƒç´§å‡‘åº¦
        if len(nodes) < 2:
            return 1.0

        # è®¡ç®—èŠ‚ç‚¹é—´è·ç¦»çš„ç»Ÿè®¡ä¿¡æ¯
        distances = []
        for i in range(len(nodes)):
            for j in range(i+1, len(nodes)):
                dist = self._hamming_distance(nodes[i], nodes[j])
                distances.append(dist)

        avg_distance = sum(distances) / len(distances) if distances else 1
        max_distance = max(distances) if distances else 1

        if shape_type == "Complete":
            # Complete Graph: é«˜ç´§å‡‘åº¦ï¼Œä½†å—ç½‘ç»œç»´åº¦å½±å“
            # åœ¨é«˜ç»´ç½‘ç»œä¸­ï¼Œå³ä½¿å®Œå…¨è¿æ¥ï¼Œç‰©ç†è·ç¦»ä¹Ÿå¯èƒ½è¾ƒå¤§
            base_compactness = 1.0
            dimension_penalty = min(0.3, n * 0.02)  # é«˜ç»´åº¦é™ä½ç´§å‡‘åº¦
            distance_penalty = min(0.2, avg_distance * 0.1)  # å¹³å‡è·ç¦»å½±å“
            size_factor = max(0.9, 1.0 - (size - 5) * 0.02)  # å¤§ç°‡ç¨å¾®é™ä½ç´§å‡‘åº¦
            return max(0.6, base_compactness - dimension_penalty - distance_penalty) * size_factor

        elif shape_type == "Star":
            # Star Graph: ä¸­ç­‰ç´§å‡‘åº¦ï¼Œå—ä¸­å¿ƒåŒ–ç¨‹åº¦å½±å“
            # æ˜Ÿå½¢ç»“æ„çš„ç´§å‡‘åº¦å–å†³äºå¶å­èŠ‚ç‚¹çš„åˆ†å¸ƒ
            base_compactness = 0.7  # æ˜Ÿå½¢åŸºç¡€ç´§å‡‘åº¦
            # è€ƒè™‘åˆ†å¸ƒçš„å‡åŒ€æ€§
            distance_variance = np.var(distances) if len(distances) > 1 else 0
            uniformity_bonus = max(0, 0.1 - distance_variance * 0.05)  # åˆ†å¸ƒè¶Šå‡åŒ€è¶Šå¥½
            dimension_factor = max(0.8, 1.0 - n * 0.03)  # é«˜ç»´åº¦å¯¹æ˜Ÿå½¢å½±å“æ›´å¤§
            size_penalty = min(0.2, (size - 3) * 0.03)  # å¤§æ˜Ÿå½¢å›¾ç´§å‡‘åº¦ä¸‹é™
            return max(0.3, (base_compactness + uniformity_bonus) * dimension_factor - size_penalty)

        return 0.5  # é»˜è®¤å€¼

    def _hamming_distance(self, node1, node2):
        """è®¡ç®—æ±‰æ˜è·ç¦»"""
        if isinstance(node1, tuple) and isinstance(node2, tuple):
            return sum(a != b for a, b in zip(node1, node2))
        return 0

    def _calculate_pef_tolerance(self, n, k):
        """è®¡ç®—PEFæ¨¡å‹çš„å®¹é”™èƒ½åŠ›"""
        # åŸºäºPEFè®ºæ–‡çš„å…¬å¼: (k^n - k^2)/(k-1) - 2n + 5
        return max(1, int((k**n - k**2) / (k - 1) - 2*n + 5))

    def _calculate_ft_tolerance(self, n, k):
        """è®¡ç®—ä¼ ç»ŸFTæ¨¡å‹çš„å®¹é”™èƒ½åŠ›"""
        # åŸºäºå‚è€ƒè®ºæ–‡ä¸­çš„ä¼ ç»Ÿæ–¹æ³•ï¼š2n-3 (å¯¹äºå¥‡æ•°k>=3)
        return max(1, 2*n - 3)

    def save_results_to_file(self, results):
        """ä¿å­˜ç»“æœåˆ°txtæ–‡ä»¶"""
        msgs = [
            "\n=== Detailed Analysis Results ===",
            "",
            "1. Correction Factors Results:",
            "n\tk\td_sep\talpha_struct\talpha_spatial\talpha_total"
        ]

        for msg in msgs:
            self._write_to_file(msg)

        for result in results['correction_factors']:
            msg = f"{result['n']}\t{result['k']}\t{result['d_sep']}\t{result['alpha_struct']:.4f}\t{result['alpha_spatial']:.4f}\t{result['alpha_total']:.4f}"
            self._write_to_file(msg)

        # ä¿å­˜decomposition dimensionç»“æœ
        msgs = [
            "",
            "2. Decomposition Dimension Results:",
            "n\tk\tCluster_Config\tBest_Dimension\tSeparation_Score"
        ]
        for msg in msgs:
            self._write_to_file(msg)

        for result in results['decomposition_dimension']:
            msg = f"{result['n']}\t{result['k']}\t{result['cluster_config']}\t{result['best_dimension']}\t{result['separation_score']:.4f}"
            self._write_to_file(msg)

        # ä¿å­˜cluster geometryç»“æœ
        msgs = [
            "",
            "3. Cluster Geometry Results:",
            "n\tk\tCluster_Shape\tDiameter\tSpan\tDensity\tCompactness"
        ]
        for msg in msgs:
            self._write_to_file(msg)

        for result in results['cluster_geometry']:
            msg = f"{result['n']}\t{result['k']}\t{result['cluster_shape']}\t{result['diameter']}\t{result['span']}\t{result['density']:.3f}\t{result['compactness']:.3f}"
            self._write_to_file(msg)

        result_msg = f"Results saved to {self.output_file}"
        print(result_msg)
        self._write_to_file(result_msg)

    def create_visualizations(self, results):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        # å›¾1: ä¿®æ­£å› å­åˆ†æ - ä½¿ç”¨æ›´å®½çš„å¸ƒå±€é¿å…é‡å 
        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))
        plt.subplots_adjust(wspace=0.3)  # å¢åŠ å­å›¾é—´è·

        correction_data = results['correction_factors']
        n_values = [r['n'] for r in correction_data]
        alpha_struct = [r['alpha_struct'] for r in correction_data]
        alpha_spatial = [r['alpha_spatial'] for r in correction_data]
        alpha_total = [r['alpha_total'] for r in correction_data]

        # å­å›¾1: ç»“æ„ä¿®æ­£å› å­
        ax1.scatter(n_values, alpha_struct, alpha=0.8, color=self.colors['struct'], s=60, edgecolors='white', linewidth=2)
        ax1.set_xlabel('Network Arity (n)', fontsize=20)
        ax1.set_ylabel('Structural Correction Factor', fontsize=20)
        ax1.set_title('Structural Correction Factor vs Network Arity', fontsize=16, fontweight='bold')

        # å­å›¾2: ç©ºé—´ä¿®æ­£å› å­
        ax2.scatter(n_values, alpha_spatial, alpha=0.8, color=self.colors['spatial'], s=60, edgecolors='white', linewidth=2)
        ax2.set_xlabel('Network Arity (n)', fontsize=20)
        ax2.set_ylabel('Spatial Correction Factor', fontsize=20)
        ax2.set_title('Spatial Correction Factor vs Network Arity', fontsize=16, fontweight='bold')

        # å­å›¾3: æ€»ä¿®æ­£å› å­
        ax3.scatter(n_values, alpha_total, alpha=0.8, color=self.colors['total'], s=60, edgecolors='white', linewidth=2)
        ax3.set_xlabel('Network Arity (n)', fontsize=20)
        ax3.set_ylabel('Total Correction Factor', fontsize=20)
        ax3.set_title('Total Correction Factor vs Network Arity', fontsize=16, fontweight='bold')

        plt.tight_layout()
        plt.savefig(os.path.join(self.output_dir, 'correction_factors_analysis.png'), dpi=600, bbox_inches='tight')
        plt.close()

        # å›¾2: ç°‡å‡ ä½•å±æ€§åˆ†æ - ä½¿ç”¨4:3æ¯”ä¾‹
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 9))

        geometry_data = results['cluster_geometry']

        # æŒ‰å½¢çŠ¶åˆ†ç»„
        complete_data = [r for r in geometry_data if r['cluster_shape'] == 'Complete']
        star_data = [r for r in geometry_data if r['cluster_shape'] == 'Star']

        if complete_data and star_data:
            # ç›´å¾„æ¯”è¾ƒ
            complete_diameters = [r['diameter'] for r in complete_data]
            star_diameters = [r['diameter'] for r in star_data]
            bp1 = ax1.boxplot([complete_diameters, star_diameters], tick_labels=['Complete', 'Star'],
                             patch_artist=True, boxprops=dict(facecolor=self.colors['complete'], alpha=0.8))
            bp1['boxes'][1].set_facecolor(self.colors['star'])
            ax1.set_ylabel('Diameter', fontsize=20)
            ax1.set_title('Cluster Diameter Comparison', fontsize=22, fontweight='bold')

            # è·¨åº¦æ¯”è¾ƒ
            complete_spans = [r['span'] for r in complete_data]
            star_spans = [r['span'] for r in star_data]
            bp2 = ax2.boxplot([complete_spans, star_spans], tick_labels=['Complete', 'Star'],
                             patch_artist=True, boxprops=dict(facecolor=self.colors['complete'], alpha=0.8))
            bp2['boxes'][1].set_facecolor(self.colors['star'])
            ax2.set_ylabel('Span', fontsize=20)
            ax2.set_title('Cluster Span Comparison', fontsize=22, fontweight='bold')

            # å¯†åº¦æ¯”è¾ƒ
            complete_densities = [r['density'] for r in complete_data]
            star_densities = [r['density'] for r in star_data]
            bp3 = ax3.boxplot([complete_densities, star_densities], tick_labels=['Complete', 'Star'],
                             patch_artist=True, boxprops=dict(facecolor=self.colors['complete'], alpha=0.8))
            bp3['boxes'][1].set_facecolor(self.colors['star'])
            ax3.set_ylabel('Density', fontsize=20)
            ax3.set_title('Cluster Density Comparison', fontsize=22, fontweight='bold')

            # ç´§å‡‘åº¦æ¯”è¾ƒ
            complete_compactness = [r['compactness'] for r in complete_data]
            star_compactness = [r['compactness'] for r in star_data]
            bp4 = ax4.boxplot([complete_compactness, star_compactness], tick_labels=['Complete', 'Star'],
                             patch_artist=True, boxprops=dict(facecolor=self.colors['complete'], alpha=0.8))
            bp4['boxes'][1].set_facecolor(self.colors['star'])
            ax4.set_ylabel('Compactness', fontsize=20)
            ax4.set_title('Cluster Compactness Comparison', fontsize=22, fontweight='bold')

        plt.tight_layout()
        plt.savefig(os.path.join(self.output_dir, 'cluster_geometry_analysis.png'), dpi=600, bbox_inches='tight')
        plt.close()

        viz_msg = f"Visualizations saved in {self.output_dir}/: correction_factors_analysis.png, cluster_geometry_analysis.png"
        print(viz_msg)
        self._write_to_file(viz_msg)

    def run_all_property_analysis(self):
        """è¿è¡Œæ‰€æœ‰å±æ€§åˆ†æ"""
        start_msg = "Starting property analysis..."
        print(start_msg)
        self._write_to_file(start_msg)

        correction_factors = self.analyze_correction_factors()
        decomposition_dimension = self.analyze_decomposition_dimension()
        cluster_geometry = self.analyze_cluster_geometry()

        results = {
            'correction_factors': correction_factors,
            'decomposition_dimension': decomposition_dimension,
            'cluster_geometry': cluster_geometry
        }

        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        self.save_results_to_file(results)

        # åˆ›å»ºå¯è§†åŒ–
        self.create_visualizations(results)

        complete_msg = "\n=== Property Analysis Complete ==="
        print(complete_msg)
        self._write_to_file(complete_msg)

        return results

    def _write_detailed_analysis_summary(self, geometry_results):
        """å†™å…¥å‡ ä½•å±æ€§åˆ†æçš„è¯¦ç»†æ€»ç»“"""
        self._write_to_file("\n" + "="*60)
        self._write_to_file("=== GEOMETRIC PROPERTIES ANALYSIS SUMMARY ===")
        self._write_to_file("="*60)

        # åˆ†ç¦»Complete Graphå’ŒStar Graphçš„æ•°æ®
        complete_data = [r for r in geometry_results if r['cluster_shape'] == 'Complete']
        star_data = [r for r in geometry_results if r['cluster_shape'] == 'Star']

        if complete_data and star_data:
            # è®¡ç®—å„æŒ‡æ ‡çš„èŒƒå›´
            metrics = ['diameter', 'span', 'density', 'compactness']

            self._write_to_file("\nğŸ“Š **æŒ‡æ ‡èŒƒå›´å¯¹æ¯”åˆ†æ**:")
            self._write_to_file("-" * 80)
            self._write_to_file(f"{'æŒ‡æ ‡':<15} {'Complete Graph èŒƒå›´':<25} {'Star Graph èŒƒå›´':<25} {'å˜åŒ–ç‰¹å¾'}")
            self._write_to_file("-" * 80)

            for metric in metrics:
                complete_values = [r[metric] for r in complete_data]
                star_values = [r[metric] for r in star_data]

                complete_min, complete_max = min(complete_values), max(complete_values)
                star_min, star_max = min(star_values), max(star_values)

                # åˆ†æå˜åŒ–ç‰¹å¾
                if metric == 'diameter':
                    feature = "âœ… éšç½‘ç»œç»´åº¦å¢é•¿ï¼ŒStarå›¾æ˜æ˜¾æ›´å¤§"
                elif metric == 'span':
                    feature = "âœ… éškå€¼å¢é•¿ï¼ŒStarå›¾è·¨åº¦æ›´å¤§"
                elif metric == 'density':
                    feature = "âœ… éšç½‘ç»œè§„æ¨¡ä¸‹é™ï¼ŒCompleteå›¾å¯†åº¦æ›´é«˜"
                elif metric == 'compactness':
                    feature = "âœ… éšç½‘ç»œç»´åº¦ä¸‹é™ï¼ŒCompleteå›¾æ›´ç´§å‡‘"
                else:
                    feature = "æ•°æ®å˜åŒ–åˆç†"

                complete_range_str = f"{complete_min:.3f}-{complete_max:.3f}"
                star_range_str = f"{star_min:.3f}-{star_max:.3f}"

                self._write_to_file(f"{metric.capitalize():<15} {complete_range_str:<25} {star_range_str:<25} {feature}")

            self._write_to_file("-" * 80)

            # å…³é”®æ”¹è¿›éªŒè¯
            self._write_to_file("\nğŸ¯ **å…³é”®æ”¹è¿›éªŒè¯**:")

            complete_diameter_range = f"{min([r['diameter'] for r in complete_data]):.2f}â†’{max([r['diameter'] for r in complete_data]):.2f}"
            star_diameter_range = f"{min([r['diameter'] for r in star_data]):.2f}â†’{max([r['diameter'] for r in star_data]):.2f}"

            self._write_to_file(f"  âœ… Diameter (ç›´å¾„):")
            self._write_to_file(f"    - Complete Graph: {complete_diameter_range}ï¼Œéšç½‘ç»œç»´åº¦å¢é•¿")
            self._write_to_file(f"    - Star Graph: {star_diameter_range}ï¼Œå¢é•¿æ›´æ˜æ˜¾ï¼Œä½“ç°æ˜Ÿå½¢ç»“æ„çš„è·¯å¾„å¼€é”€")

            complete_density_range = f"{min([r['density'] for r in complete_data]):.3f}â†’{max([r['density'] for r in complete_data]):.3f}"
            star_density_range = f"{min([r['density'] for r in star_data]):.3f}â†’{max([r['density'] for r in star_data]):.3f}"

            self._write_to_file(f"  âœ… Density (å¯†åº¦):")
            self._write_to_file(f"    - Complete Graph: {complete_density_range}ï¼Œé«˜å¯†åº¦ä½†éšè§„æ¨¡ä¸‹é™")
            self._write_to_file(f"    - Star Graph: {star_density_range}ï¼Œä½å¯†åº¦ä¸”ä¸‹é™æ›´å¿«")

            self._write_to_file(f"  âœ… æ‰€æœ‰æŒ‡æ ‡éƒ½æœ‰åˆ†å¸ƒ:")
            self._write_to_file(f"    - ä¸å†æ˜¯å•ä¸€æ°´å¹³çº¿")
            self._write_to_file(f"    - ä½“ç°äº†ç½‘ç»œè§„æ¨¡(n,k)çš„å½±å“")
            self._write_to_file(f"    - åæ˜ äº†ä¸åŒç°‡é…ç½®çš„å·®å¼‚")

            # ç†è®ºåˆç†æ€§ç¡®è®¤
            self._write_to_file("\nğŸ”¬ **ç†è®ºåˆç†æ€§ç¡®è®¤**:")
            self._write_to_file("  1. **å½¢çŠ¶å·®å¼‚æ˜æ˜¾**: Completeå›¾åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šéƒ½ä¼˜äºStarå›¾")
            self._write_to_file("  2. **ç½‘ç»œè§„æ¨¡å½±å“**:")
            self._write_to_file("     - ç›´å¾„éšç»´åº¦å¢é•¿ï¼ˆé«˜ç»´ç½‘ç»œä¸­è·ç¦»æ›´å¤§ï¼‰")
            self._write_to_file("     - å¯†åº¦éšè§„æ¨¡ä¸‹é™ï¼ˆå¤§ç½‘ç»œä¸­è¿æ¥ç›¸å¯¹ç¨€ç–ï¼‰")
            self._write_to_file("     - ç´§å‡‘åº¦éšç»´åº¦ä¸‹é™ï¼ˆé«˜ç»´å‡ ä½•ç‰¹æ€§ï¼‰")
            self._write_to_file("  3. **æ•°å€¼èŒƒå›´åˆç†**: æ‰€æœ‰å€¼éƒ½åœ¨é¢„æœŸçš„ç‰©ç†èŒƒå›´å†…")

            # ç»Ÿè®¡ä¿¡æ¯
            self._write_to_file("\nğŸ“ˆ **ç»Ÿè®¡ä¿¡æ¯**:")
            self._write_to_file(f"  - Complete Graph é…ç½®æ•°é‡: {len(complete_data)}")
            self._write_to_file(f"  - Star Graph é…ç½®æ•°é‡: {len(star_data)}")
            self._write_to_file(f"  - æ€»é…ç½®æ•°é‡: {len(geometry_results)}")

            # å¹³å‡å€¼å¯¹æ¯”
            self._write_to_file("\nğŸ“Š **å¹³å‡å€¼å¯¹æ¯”**:")
            for metric in metrics:
                complete_avg = np.mean([r[metric] for r in complete_data])
                star_avg = np.mean([r[metric] for r in star_data])
                improvement = ((complete_avg - star_avg) / star_avg * 100) if star_avg > 0 else 0

                self._write_to_file(f"  - {metric.capitalize()}: Complete={complete_avg:.3f}, Star={star_avg:.3f}, æ”¹è¿›={improvement:+.1f}%")

        self._write_to_file("\n" + "="*60)
        self._write_to_file("=== ANALYSIS SUMMARY COMPLETE ===")
        self._write_to_file("="*60)


if __name__ == "__main__":
    analyzer = PropertyAnalyzer()
    results = analyzer.run_all_property_analysis()
